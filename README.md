# Celeryåˆ†å¸ƒå¼ä»»åŠ¡æ¡†æ¶

ä¸€ä¸ªåŸºäºCeleryçš„ç°ä»£åŒ–åˆ†å¸ƒå¼ä»»åŠ¡å¤„ç†æ¡†æ¶ï¼Œæ”¯æŒå¿«é€Ÿæ­å»ºæ•°æ®é‡‡é›†ã€å¤„ç†å’Œç®¡ç†çš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚æä¾›å®Œæ•´çš„Dockerå®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆå’ŒKubernetesæ”¯æŒã€‚

## é¡¹ç›®ç»“æ„

```
celery_project_structure/
â”œâ”€â”€ deploy/                 # Dockeréƒ¨ç½²æ–‡ä»¶
â”‚   â”œâ”€â”€ BaseDockerfile      # åŸºç¡€å®¹å™¨é•œåƒå®šä¹‰
â”‚   â”œâ”€â”€ Dockerfile          # åº”ç”¨å®¹å™¨é•œåƒå®šä¹‰
â”‚   â””â”€â”€ docker-compose.yaml # å¤šæœåŠ¡ç¼–æ’
â”œâ”€â”€ k8s/                    # Kuberneteséƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ deploy.sh           # éƒ¨ç½²è„šæœ¬
â”‚   â””â”€â”€ deployment.yaml     # K8séƒ¨ç½²æ–‡ä»¶
â”œâ”€â”€ src/                    # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ main/               # ä¸»å·¥ç¨‹ä»£ç 
â”‚   â”‚   â””â”€â”€ tasks/          # Celeryä»»åŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ settings/           # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ celery_config/   # Celeryé…ç½®
â”‚   â”‚   â””â”€â”€ config.py        # åº”ç”¨é…ç½®
â”‚   â””â”€â”€ utils/              # å·¥å…·æ¨¡å—
â”‚       â”œâ”€â”€ ai_tools.py     # AIå·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ chromium_manager.py  # æµè§ˆå™¨ç®¡ç†
â”‚       â”œâ”€â”€ craw_tools.py   # çˆ¬è™«å·¥å…·
â”‚       â”œâ”€â”€ db_tools.py     # æ•°æ®åº“å·¥å…·
â”‚       â””â”€â”€ wechat_crawler_demo.py  # å¾®ä¿¡çˆ¬è™«ç¤ºä¾‹
â”œâ”€â”€ examples/               # ç¤ºä¾‹ä»£ç 
â”‚   â””â”€â”€ database_example.py # æ•°æ®åº“æ“ä½œç¤ºä¾‹
â”œâ”€â”€ sql/                    # SQLè„šæœ¬
â”‚   â””â”€â”€ ex_shipping_information.sql  # ç¤ºä¾‹SQL
â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
â”œâ”€â”€ .env.example           # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ start_flower.py        # Flowerç›‘æ§æœåŠ¡å¯åŠ¨è„šæœ¬
â”œâ”€â”€ check_env.py           # ç¯å¢ƒæ£€æŸ¥è„šæœ¬
â”œâ”€â”€ test-deploy.sh         # æµ‹è¯•éƒ¨ç½²è„šæœ¬
â””â”€â”€ README.md              # é¡¹ç›®æ–‡æ¡£
```

## åŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½
- âœ… åŸºäºCeleryçš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—
- âœ… å¤šé˜Ÿåˆ—ä»»åŠ¡è·¯ç”±é…ç½®ï¼ˆé»˜è®¤é˜Ÿåˆ—ã€çˆ¬è™«é˜Ÿåˆ—ï¼‰
- âœ… FastAPI RESTful APIæ¥å£
- âœ… Dockerå®¹å™¨åŒ–éƒ¨ç½²
- âœ… Kubernetesé›†ç¾¤éƒ¨ç½²æ”¯æŒ
- âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦ï¼ˆCelery Beatï¼‰
- âœ… Flowerå®æ—¶ç›‘æ§å’Œä»»åŠ¡ç®¡ç†
- âœ… ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å’Œç®¡ç†
- âœ… é”™è¯¯é‡è¯•å’Œæ—¥å¿—è®°å½•

### æ•°æ®é‡‡é›†èƒ½åŠ›
- âœ… èˆ¹è®¯ç½‘æ•°æ®é‡‡é›†ä»»åŠ¡
- âœ… å¾®ä¿¡çˆ¬è™«ç¤ºä¾‹
- âœ… æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆChromiumï¼‰
- âœ… AIå·¥å…·é›†æˆ
- âœ… æ•°æ®åº“æ“ä½œå·¥å…·

### å¼€å‘å·¥å…·
- âœ… ç¯å¢ƒæ£€æŸ¥è„šæœ¬
- âœ… æµ‹è¯•éƒ¨ç½²è„šæœ¬
- âœ… ç¤ºä¾‹ä»£ç å’ŒSQLè„šæœ¬
- âœ… è‡ªåŠ¨ä»»åŠ¡æ³¨å†Œæœºåˆ¶

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd celery_project_structure

# å¤åˆ¶ç¯å¢ƒé…ç½®
cp .env.example .env

# æ£€æŸ¥ç¯å¢ƒä¾èµ–
python check_env.py
```
# å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt

# æˆ–è€…å®‰è£…ä¸­é—´é•œåƒ
docker build -f deploy/BaseDockerfile -t craw_service:base .
```


### 2. å¯åŠ¨æœåŠ¡

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨Docker Composeï¼ˆæ¨èï¼‰

```bash
cd deploy
docker-compose up -d
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨æµ‹è¯•éƒ¨ç½²è„šæœ¬

```bash
# è¿è¡Œæµ‹è¯•éƒ¨ç½²è„šæœ¬
./test-deploy.sh
```

#### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨å¯åŠ¨å„æœåŠ¡

```bash
# å¯åŠ¨é»˜è®¤é˜Ÿåˆ—Workerï¼ˆå¤„ç†æ™®é€šä»»åŠ¡ï¼‰
celery -A src.settings.celery_config.celery_app worker --loglevel=info -Q default

# å¯åŠ¨çˆ¬è™«é˜Ÿåˆ—Workerï¼ˆå¤„ç†æ•°æ®é‡‡é›†ä»»åŠ¡ï¼‰
celery -A src.settings.celery_config.celery_app worker --loglevel=info -Q crawler_queue

# å¯åŠ¨Celery Beatï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
celery -A src.settings.celery_config.celery_app beat --loglevel=info

# å¯åŠ¨FastAPIæœåŠ¡
uvicorn src.main.api:app --host 0.0.0.0 --port 8000 --reload

# å¯åŠ¨Flowerç›‘æ§æœåŠ¡
celery flower --address=0.0.0.0 --port=5555 --basic_auth=admin:admin123
```

### 3. è®¿é—®æœåŠ¡

- **FastAPIæœåŠ¡**: http://localhost:8000
- **APIæ–‡æ¡£**: http://localhost:8000/docs  # å·²æ³¨é‡Š
- **Flowerç›‘æ§**: http://localhost:5555 (ç”¨æˆ·å: admin, å¯†ç : admin123)

## APIä½¿ç”¨ç¤ºä¾‹

### 1. å¯åŠ¨AIåŸºç¡€æ•°æ®é‡‡é›†ä»»åŠ¡
```bash
curl -X POST "http://localhost:8000/api/tasks/craw-aibase"
```

### 2. å¯åŠ¨ç¿»è¯‘ä»»åŠ¡
```bash
curl -X POST "http://localhost:8000/api/tasks/translate" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello World",
    "target_language": "zh"
  }'
```

### 3. è·å–ä»»åŠ¡ç»“æœ
```bash
curl "http://localhost:8000/api/tasks/result?task_id=task-uuid-here"
```

### 4. æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
```bash
curl "http://localhost:8000/api/tasks/status"
```

## ä»»åŠ¡ç±»å‹

### 1. AIåŸºç¡€æ•°æ®é‡‡é›†ä»»åŠ¡ (`craw_aibase_thread`)
- å®šæ—¶é‡‡é›†AIåŸºç¡€æ•°æ®
- æ”¯æŒå¤šé¡µé¢æ•°æ®è§£æ
- è‡ªåŠ¨æ•°æ®å…¥åº“
- é”™è¯¯é‡è¯•å’Œè¶…æ—¶æ§åˆ¶
- **é˜Ÿåˆ—åˆ†é…**: `crawler_queue`ï¼ˆçˆ¬è™«é˜Ÿåˆ—ï¼‰

### 2. ç¿»è¯‘ä»»åŠ¡ (`translate_tasks`)
- æ–‡æœ¬ç¿»è¯‘å¤„ç†ä»»åŠ¡
- æ”¯æŒå¤šç§è¯­è¨€ç¿»è¯‘
- æ‰¹é‡å¤„ç†èƒ½åŠ›
- **é˜Ÿåˆ—åˆ†é…**: `default`ï¼ˆé»˜è®¤é˜Ÿåˆ—ï¼‰

### 3. æ–°ä»»åŠ¡æ¨¡å— (`new_tasks`)
- é¢„ç•™çš„æ–°ä»»åŠ¡å¼€å‘ç›®å½•
- æ”¯æŒå¿«é€Ÿæ‰©å±•æ–°åŠŸèƒ½
- **é˜Ÿåˆ—åˆ†é…**: æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨åˆ†é…

## é˜Ÿåˆ—é…ç½®

é¡¹ç›®é…ç½®äº†å¤šé˜Ÿåˆ—ä»»åŠ¡è·¯ç”±ï¼Œå®ç°ä»»åŠ¡åˆ†ç±»å¤„ç†ï¼š

### é˜Ÿåˆ—å®šä¹‰
- **`default`é˜Ÿåˆ—**: å¤„ç†æ™®é€šæµ‹è¯•ä»»åŠ¡å’Œç³»ç»Ÿä»»åŠ¡
- **`crawler_queue`é˜Ÿåˆ—**: ä¸“é—¨å¤„ç†æ•°æ®é‡‡é›†å’Œçˆ¬è™«ä»»åŠ¡

### ä»»åŠ¡è·¯ç”±é…ç½®

ä»»åŠ¡è·¯ç”±é…ç½®åœ¨ `src/settings/celery_config/celery_app.py` ä¸­ï¼š

```python
task_routes = {
    'src.main.tasks.time_tasks.craw_aibase_thread.time_task': {'queue': 'crawler_queue'},
    'src.main.tasks.time_tasks.translate_tasks.translate_task': {'queue': 'default'},
}
```

### Dockeréƒ¨ç½²é˜Ÿåˆ—æœåŠ¡

åœ¨ `deploy/docker-compose.yaml` ä¸­é…ç½®äº†ç‹¬ç«‹çš„é˜Ÿåˆ—æœåŠ¡ï¼š

```yaml
# é»˜è®¤é˜Ÿåˆ—WorkeræœåŠ¡
celery-worker:
  command: celery -A src.settings.celery_config.celery_app worker --loglevel=info -Q default

# çˆ¬è™«é˜Ÿåˆ—WorkeræœåŠ¡  
celery-crawler-worker:
  command: celery -A src.settings.celery_config.celery_app worker --loglevel=info -Q crawler_queue
```

### é˜Ÿåˆ—ä¼˜åŠ¿
- **èµ„æºéš”ç¦»**: çˆ¬è™«ä»»åŠ¡å’Œæ™®é€šä»»åŠ¡åˆ†ç¦»ï¼Œé¿å…ç›¸äº’å½±å“
- **ä¼˜å…ˆçº§ç®¡ç†**: å¯ä¸ºä¸åŒé˜Ÿåˆ—è®¾ç½®ä¸åŒçš„ä¼˜å…ˆçº§å’Œèµ„æºé™åˆ¶
- **æ•…éšœéš”ç¦»**: å•ä¸ªé˜Ÿåˆ—æ•…éšœä¸å½±å“å…¶ä»–é˜Ÿåˆ—çš„æ­£å¸¸è¿è¡Œ
- **æ‰©å±•æ€§**: å¯æ ¹æ®éœ€è¦è½»æ¾æ·»åŠ æ–°çš„ä¸“ç”¨é˜Ÿåˆ—

## å®šæ—¶ä»»åŠ¡é…ç½®

æ¡†æ¶é¢„é…ç½®äº†ä»¥ä¸‹å®šæ—¶ä»»åŠ¡ï¼š

- **AIåŸºç¡€æ•°æ®é‡‡é›†**: å®šæ—¶æ‰§è¡ŒAIåŸºç¡€æ•°æ®é‡‡é›†ä»»åŠ¡
- **ç¿»è¯‘ä»»åŠ¡**: å®šæ—¶æ‰§è¡Œæ–‡æœ¬ç¿»è¯‘å¤„ç†

é…ç½®ä½ç½®ï¼š`src/settings/celery_config/celery_app.py` ä¸­çš„ `beat_schedule`

å½“å‰å¯ç”¨çš„å®šæ—¶ä»»åŠ¡ï¼š
```python
# AIåŸºç¡€æ•°æ®é‡‡é›†ä»»åŠ¡
'craw-aibase-daily': {
    'task': 'src.main.tasks.time_tasks.craw_aibase_thread.time_task',
    'schedule': crontab(minute='*/5'),  # æ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    'args': ()
},

# ç¿»è¯‘ä»»åŠ¡
'translate-daily': {
    'task': 'src.main.tasks.time_tasks.translate_tasks.translate_task',
    'schedule': crontab(hour=0, minute=0),  # æ¯å¤©åˆå¤œæ‰§è¡Œ
    'args': ()
}
```

## è‡ªå®šä¹‰å¼€å‘

### ä»»åŠ¡æ¨¡å—ç»“æ„

é¡¹ç›®é‡‡ç”¨æ¨¡å—åŒ–ä»»åŠ¡ç»“æ„ï¼Œæ”¯æŒå¤šç±»å‹ä»»åŠ¡ç»„ç»‡ï¼š

```
src/main/tasks/
â”œâ”€â”€ __init__.py      # ä»»åŠ¡è‡ªåŠ¨æ³¨å†Œæ–‡ä»¶
â”œâ”€â”€ api.py           # FastAPIæœåŠ¡
â”œâ”€â”€ time_tasks/      # å®šæ—¶ä»»åŠ¡ç›®å½•
â”‚   â”œâ”€â”€ __init__.py  # å®šæ—¶ä»»åŠ¡æ³¨å†Œ
â”‚   â”œâ”€â”€ craw_aibase_thread.py  # AIåŸºç¡€æ•°æ®é‡‡é›†ä»»åŠ¡
â”‚   â””â”€â”€ translate_tasks.py     # ç¿»è¯‘ä»»åŠ¡
â””â”€â”€ new_tasks/       # æ–°ä»»åŠ¡å¼€å‘ç›®å½•
```

### è‡ªåŠ¨ä»»åŠ¡æ³¨å†Œæœºåˆ¶ â­

**é‡è¦æ›´æ–°ï¼šä¸å†éœ€è¦æ‰‹åŠ¨æ³¨å†Œä»»åŠ¡ï¼**

æ¡†æ¶å·²å®ç°æ™ºèƒ½ä»»åŠ¡è‡ªåŠ¨å‘ç°æœºåˆ¶ï¼Œåªéœ€å°†ä»»åŠ¡æ–‡ä»¶æ”¾ç½®åœ¨ `src/main/tasks/time_tasks/` ç›®å½•ä¸‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š

1. **è‡ªåŠ¨æ‰«æ**ï¼šæ‰«æ `time_tasks` ç›®å½•ä¸‹çš„æ‰€æœ‰Pythonæ–‡ä»¶
2. **è‡ªåŠ¨è¯†åˆ«**ï¼šè¯†åˆ«ä»¥ `_task` æˆ– `_tasks` ç»“å°¾çš„ä»»åŠ¡å‡½æ•°
3. **è‡ªåŠ¨æ³¨å†Œ**ï¼šè‡ªåŠ¨æ³¨å†Œåˆ°Celeryä»»åŠ¡ç³»ç»Ÿ
4. **è‡ªåŠ¨å¯¼å‡º**ï¼šè‡ªåŠ¨æ·»åŠ åˆ° `__all__` åˆ—è¡¨

### æ·»åŠ æ–°çš„ä»»åŠ¡

1. **åˆ›å»ºæ–°çš„ä»»åŠ¡æ–‡ä»¶**ï¼šåœ¨ `src/main/tasks/time_tasks/` æˆ– `src/main/tasks/new_tasks/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„Pythonæ–‡ä»¶

```python
# src/main/tasks/time_tasks/custom_task.py
from celery import shared_task

@shared_task
def custom_collection_task(parameters):
    """è‡ªå®šä¹‰æ•°æ®é‡‡é›†ä»»åŠ¡"""
    # å®ç°è‡ªå®šä¹‰é‡‡é›†é€»è¾‘
    return {"status": "success", "data": "custom data"}

@shared_task
def another_custom_task():
    """å¦ä¸€ä¸ªè‡ªå®šä¹‰ä»»åŠ¡"""
    return {"status": "completed"}
```

2. **ç³»ç»Ÿè‡ªåŠ¨æ³¨å†Œ**ï¼šä»»åŠ¡ä¼šè‡ªåŠ¨è¢«å‘ç°å’Œæ³¨å†Œ

3. **éªŒè¯ä»»åŠ¡æ³¨å†Œ**ï¼šå¯åŠ¨æœåŠ¡åï¼Œç³»ç»Ÿä¼šæ˜¾ç¤ºå·²æ³¨å†Œçš„ä»»åŠ¡åˆ—è¡¨

```
âœ… æˆåŠŸå¯¼å…¥æ¨¡å—: src.main.tasks.time_tasks.custom_task
ğŸ¯ å·²æ³¨å†Œçš„ä»»åŠ¡å‡½æ•°: ['custom_collection_task', 'another_custom_task']
```

4. **åœ¨APIä¸­æ·»åŠ æ¥å£**ï¼ˆå¯é€‰ï¼‰ï¼š

```python
# åœ¨ src/main/tasks/api.py ä¸­æ·»åŠ APIæ¥å£
@router.post("/custom-task")
async def start_custom_task():
    task = custom_collection_task.delay({})
    return {"task_id": task.id, "status": "started"}
```

### ä¿®æ”¹æˆ–æ–°å¢å®šæ—¶ä»»åŠ¡

ç¼–è¾‘ `src/settings/celery_config/celery_app.py` ä¸­çš„ `beat_schedule` é…ç½®ï¼š

```python
beat_schedule={
    'custom-task': {
        'task': 'src.main.tasks.time_tasks.custom_task.custom_collection_task',
        'schedule': crontab(minute=0, hour=0),  # æ¯å¤©åˆå¤œæ‰§è¡Œ
        'args': ()
    }
}
```

### éªŒè¯ä»»åŠ¡æ³¨å†Œï¼ˆè‡ªåŠ¨éªŒè¯ï¼‰

**æ— éœ€æ‰‹åŠ¨éªŒè¯ï¼** ç³»ç»Ÿå¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ˜¾ç¤ºå·²æ³¨å†Œçš„ä»»åŠ¡ï¼š

```
âœ… æˆåŠŸå¯¼å…¥æ¨¡å—: src.main.tasks.time_tasks.test_tasks
âœ… æˆåŠŸå¯¼å…¥æ¨¡å—: src.main.tasks.time_tasks.craw_chone_thread
ğŸ¯ å·²æ³¨å†Œçš„ä»»åŠ¡å‡½æ•°: ['hello_task', 'time_task']
```

### é«˜çº§åŠŸèƒ½ï¼šåŠ¨æ€å¯¼å…¥ä»»æ„æ–‡ä»¶å¤¹

æ¡†æ¶æ”¯æŒåŠ¨æ€å¯¼å…¥ä»»æ„æ–‡ä»¶å¤¹ä¸‹çš„ä»»åŠ¡ï¼š

```python
from src.main.tasks import import_modules_from_folder

# å¯¼å…¥è‡ªå®šä¹‰æ–‡ä»¶å¤¹ä¸‹çš„ä»»åŠ¡
custom_tasks = import_modules_from_folder(
    folder_path="/path/to/custom/tasks",
    base_package_path="custom.tasks.package",
    task_suffixes=('_task', '_job')  # è‡ªå®šä¹‰ä»»åŠ¡åç¼€
)
```

## éƒ¨ç½²è¯´æ˜

### Dockeréƒ¨ç½²

é¡¹ç›®æä¾›äº†å®Œæ•´çš„Dockeréƒ¨ç½²æ–¹æ¡ˆï¼š

```bash
# æ„å»ºå’Œå¯åŠ¨æ‰€æœ‰æœåŠ¡
cd deploy
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# åœæ­¢æœåŠ¡
docker-compose down
```

### Kuberneteséƒ¨ç½²

é¡¹ç›®æ”¯æŒKubernetesé›†ç¾¤éƒ¨ç½²ï¼š

```bash
# ä½¿ç”¨éƒ¨ç½²è„šæœ¬
cd k8s
./deploy.sh

# æˆ–è€…æ‰‹åŠ¨åº”ç”¨éƒ¨ç½²é…ç½®
kubectl apply -f deployment.yaml

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
kubectl get pods
kubectl get services
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

1. ä¿®æ”¹ `deploy/docker-compose.yaml` ä¸­çš„ç¯å¢ƒå˜é‡
2. é…ç½®æŒä¹…åŒ–å­˜å‚¨ï¼ˆRedisæ•°æ®ï¼‰
3. è®¾ç½®é€‚å½“çš„èµ„æºé™åˆ¶
4. é…ç½®æ—¥å¿—æ”¶é›†å’Œç›‘æ§
5. é…ç½®Kubernetes Ingresså’ŒService

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Redisè¿æ¥å¤±è´¥**
   - æ£€æŸ¥RedisæœåŠ¡æ˜¯å¦è¿è¡Œ
   - éªŒè¯ `CELERY_BROKER_URL` é…ç½®

2. **ä»»åŠ¡æ‰§è¡Œå¤±è´¥**
   - æŸ¥çœ‹Celery Workeræ—¥å¿—
   - æ£€æŸ¥ä»»åŠ¡å‚æ•°å’Œä¾èµ–

3. **APIæœåŠ¡æ— æ³•è®¿é—®**
   - ç¡®è®¤FastAPIæœåŠ¡ç«¯å£ï¼ˆ8000ï¼‰æ˜¯å¦å¼€æ”¾
   - æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹Celery Workeræ—¥å¿—
celery -A celery.celery_app worker --loglevel=debug

# æŸ¥çœ‹Dockerå®¹å™¨æ—¥å¿—
docker-compose logs [service-name]
```

## æ‰©å±•å»ºè®®

- æ·»åŠ æ•°æ®åº“æ”¯æŒï¼ˆPostgreSQL/MySQLï¼‰
- å®ç°æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢æ¥å£
- æ·»åŠ ç”¨æˆ·è®¤è¯å’Œæƒé™æ§åˆ¶
- é›†æˆç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
- æ”¯æŒæ›´å¤šæ•°æ®æºç±»å‹ï¼ˆæ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰ï¼‰

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªæ¡†æ¶ã€‚
